# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NSeoAfHoc-J3E7HeG6BPovMVNO9sqW-5
"""

import json
import requests
import urllib.request
from uszipcode import SearchEngine
import matplotlib.pyplot as plt
import dateutil
import pandas as pd
import numpy as np
from urllib.parse import urljoin
from collections import defaultdict
import asyncio
#import aiohttp
from geopy.distance import geodesic
import requests, time
from requests.exceptions import HTTPError
import warnings
warnings.filterwarnings("ignore")
from sklearn.impute import KNNImputer
import pytz
import re
from geopy.geocoders import Nominatim
from datetime import date
from datetime import datetime, timedelta, timezone
from scipy.stats import rankdata
from sklearn.metrics import mean_squared_error
from math import sqrt

# Dictionary for neighbouring states
neigh_state = {
    'AL': ['FL', 'GA', 'MS', 'TN'],
    'AK': [],
    'AZ': ['CA', 'CO', 'NM', 'NV', 'UT'],
    'AR': ['LA', 'MS', 'MO', 'OK', 'TN', 'TX'],
    'CA': ['AZ', 'NV', 'OR'],
    'CO': ['AZ', 'KS', 'NE', 'NM', 'OK', 'UT', 'WY'],
    'CT': ['MA', 'NY', 'RI'],
    'DE': ['MD', 'NJ', 'PA'],
    'FL': ['AL', 'GA'],
    'GA': ['AL', 'FL', 'NC', 'SC', 'TN'],
    'HI': [],
    'ID': ['MT', 'NV', 'OR', 'UT', 'WA', 'WY'],
    'IL': ['IN', 'IA', 'KY', 'MO', 'WI'],
    'IN': ['IL', 'KY', 'MI', 'OH'],
    'IA': ['IL', 'MN', 'MO', 'NE', 'SD', 'WI'],
    'KS': ['CO', 'MO', 'NE', 'OK'],
    'KY': ['IL', 'IN', 'MO', 'OH', 'TN', 'VA', 'WV'],
    'LA': ['AR', 'MS', 'TX'],
    'ME': ['NH'],
    'MD': ['DE', 'PA', 'VA', 'WV'],
    'MA': ['CT', 'NH', 'NY', 'RI', 'VT'],
    'MI': ['IN', 'OH', 'WI'],
    'MN': ['IA', 'MI', 'ND', 'SD', 'WI'],
    'MS': ['AL', 'AR', 'LA', 'TN'],
    'MO': ['AR', 'IA', 'IL', 'KS', 'KY', 'NE', 'OK', 'TN'],
    'MT': ['ID', 'ND', 'SD', 'WY'],
    'NE': ['CO', 'IA', 'KS', 'MO', 'SD', 'WY'],
    'NV': ['AZ', 'CA', 'ID', 'OR', 'UT'],
    'NH': ['MA', 'ME', 'VT'],
    'NJ': ['DE', 'NY', 'PA'],
    'NM': ['AZ', 'CO', 'OK', 'TX', 'UT'],
    'NY': ['CT', 'MA', 'NJ', 'PA', 'VT'],
    'NC': ['GA', 'SC', 'TN', 'VA'],
    'ND': ['MN', 'MT', 'SD'],
    'OH': ['IN', 'KY', 'MI', 'PA', 'WV'],
    'OK': ['AR', 'CO', 'KS', 'MO', 'NM', 'TX'],
    'OR': ['CA', 'ID', 'NV', 'WA'],
    'PA': ['DE', 'MD', 'NJ', 'NY', 'OH', 'WV'],
    'RI': ['CT', 'MA'],
    'SC': ['GA', 'NC'],
    'SD': ['IA', 'MN', 'MT', 'ND', 'NE', 'WY'],
    'TN': ['AL', 'AR', 'GA', 'KY', 'MS', 'MO', 'NC', 'VA'],
    'TX': ['AR', 'LA', 'NM', 'OK'],
    "WY": ["UT", "SD", "NE", "MT", "CO"],
    "WI": ["MN", "MI", "IL", "IA"],
    "WV": ["VA", "OH", "MD", "KY", "PA"],
    "WA": ["OR", "ID"],
    "VT": ["NH", "NY", "MA"],
    "VA": ["WV", "TN", "NC", "MD", "KY"],
    "UT": ["WY", "ID", "NV", "CO", "AZ"],
}

# Dictionary for state names to state codes
us_state_to_abbrev = {
    "Alabama": "AL",
    "Alaska": "AK",
    "Arizona": "AZ",
    "Arkansas": "AR",
    "California": "CA",
    "Colorado": "CO",
    "Connecticut": "CT",
    "Delaware": "DE",
    "Florida": "FL",
    "Georgia": "GA",
    "Hawaii": "HI",
    "Idaho": "ID",
    "Illinois": "IL",
    "Indiana": "IN",
    "Iowa": "IA",
    "Kansas": "KS",
    "Kentucky": "KY",
    "Louisiana": "LA",
    "Maine": "ME",
    "Maryland": "MD",
    "Massachusetts": "MA",
    "Michigan": "MI",
    "Minnesota": "MN",
    "Mississippi": "MS",
    "Missouri": "MO",
    "Montana": "MT",
    "Nebraska": "NE",
    "Nevada": "NV",
    "New Hampshire": "NH",
    "New Jersey": "NJ",
    "New Mexico": "NM",
    "New York": "NY",
    "North Carolina": "NC",
    "North Dakota": "ND",
    "Ohio": "OH",
    "Oklahoma": "OK",
    "Oregon": "OR",
    "Pennsylvania": "PA",
    "Rhode Island": "RI",
    "South Carolina": "SC",
    "South Dakota": "SD",
    "Tennessee": "TN",
    "Texas": "TX",
    "Utah": "UT",
    "Vermont": "VT",
    "Virginia": "VA",
    "Washington": "WA",
    "West Virginia": "WV",
    "Wisconsin": "WI",
    "Wyoming": "WY",
    "District of Columbia": "DC",
    "American Samoa": "AS",
    "Guam": "GU",
    "Northern Mariana Islands": "MP",
    "Puerto Rico": "PR",
    "United States Minor Outlying Islands": "UM",
    "U.S. Virgin Islands": "VI",
}

def remove_unwanted_chars(col):
      col = re.sub('#','',str(col))
      return col

def parse(string_value):
    try:
        return float(string_value)
    except:
        try:
            return dateutil.parser.parse(string_value)
        except:
            return string_value

def get_past_week_wait_times(data):
    # Extract observation times and wait times from data
    obs_times = data["observation_times"]
    wait_times = data["wait_time_mins"]
    len = obs_times.size

    # Get the most recent observation time and add 30 minutes to it
    last_obs_time = datetime.fromisoformat(str(obs_times[len-1]))
    future_time = last_obs_time + timedelta(minutes=30)

    # Get the observation time 1 week before the future time
    past_time = future_time - timedelta(weeks=1)
    
    # Find index of observation time just greater than past_time
    index = None
    for i in range(len):
        obs_time = datetime.fromisoformat(str(obs_times[i]))
        if obs_time >= past_time:
            index = i
            break
    
    # If no observation time is greater than past_time, return None
    if index is None:
        return None
    
    # Return corresponding wait time
    past_wait_time = wait_times[index]
    return past_wait_time

def get_wait_times(hosp_id, is_ER):
  
  raw_history ={}
  other_val = False
  wait_time = 0
  obs_time = ''

  root_url= "https://ertrack.net/"
  url = "/api/hospital/"+str(hosp_id)+"/history/"
  url = urljoin(root_url, url)

  UTC = pytz.utc
  datetime_utc = datetime.now(UTC)

  try:
    r = requests.get(url)
    r.raise_for_status()

  except HTTPError as exc:
    code = exc.response.status_code
    if code in [200, 429, 500, 502, 503, 504]:
      wait_time = -2
      obs_time = datetime_utc.strftime('%Y-%m-%d %H:%M:%S%z')

  else:
    for k, v in r.json().items():
        raw_history[k] = [parse(i) for i in v]
    #convert dict to dataframe 
    df_rh = pd.DataFrame.from_dict(raw_history, orient='index').transpose()
    wait_time = df_rh.iloc[-1]['wait_time_mins']
    obs_time = df_rh.iloc[-1]['observation_times']

  # Check if current time is -1 then does it have other than -1 values
  if wait_time == -1:
    all_val = df_rh['wait_time_mins'].unique()
    if len(all_val) > 1:
      other_val = True # there are other values present 

  # Check if it is closing soon based on past weeks wait time
  if wait_time != -2 and other_val:
    check_past  = get_past_week_wait_times(df_rh)
    if check_past == -1:
      wait_time = -5 # indicating it is closing soon

  # if is_ER and wait_time = -1 or -2, then set wait time to 0 (ERs are open 24/7)
  if is_ER and (wait_time == -1 or wait_time == -2):
    wait_time = 0

  # where wait time is -2 or (-1 & other values not present)
  if wait_time == -2 | (wait_time == -1 & ~other_val):
    wait_time = np.NaN


  return wait_time, other_val

# Function to impute the wait time
def Knn_imputer(df):

  # just the columns wait_time and distance, and drop any rows with null values
  data = df[['wait_time', 'distance']].dropna()  
  
  #Instantiate the KNNImputer
  imputer = KNNImputer(n_neighbors=4)

  #Fit the imputer
  imputer.fit(data)  
  
  # Check for missing data
  missing_data = df.loc[df['wait_time'].isna(), ['wait_time', 'distance']]

  #use imputer to fill the missing data
  imputed_data = imputer.transform(missing_data)
  
  # set the imputed values into the df
  df.loc[df['wait_time'].isna(), 'wait_time'] = imputed_data[:, 0]

  return df

# # Function to fetch top 8 hospitals given the users location

# def get_top8_hosp(lat, lng, data):

#   # Fetch state from lat and long
#   geolocator = Nominatim(user_agent="Geolocation")
#   location = geolocator.reverse(str(lat)+","+str(lng))
#   address = location.raw['address']
#   state = address.get('state', '')

#   # get the state code fromt he state name
#   state_code = us_state_to_abbrev.get(state)

#   # get the list of neighbouring states
#   state_list = neigh_state.get(state_code)

#   # filtering data only for that states
#   df_req = data[data.state.isin(state_list)]

#   distance = []

#   for i in range(df_req.shape[0]):
#     # lat and lng of hospitals from state
#     lat_lng_hosp = df_req.iloc[i]['lat'], df_req.iloc[i]['lng']

#     # lat and lng of user
#     lat_lng_user = lat, lng

#     # distance calculated in miles
#     cal_dist = geodesic(lat_lng_user, lat_lng_hosp).miles

#     hosp = df_req.iloc[i]['hospital_name'] 
#     hosp_id = df_req.iloc[i]['hospital_id']
#     hosp_add = df_req.iloc[i]['address']
#     lat = df_req.iloc[i]['lat']
#     lng = df_req.iloc[i]['lng']
#     hosp_type = df_req.iloc[i]['type_id']
#     is_ER = df_req.iloc[i]['Is_ER']
    
#     # appending all values to the list
#     distance.append([hosp, hosp_id, hosp_add,lat, lng, hosp_type, cal_dist, is_ER])


#   # converting the list to dataframe
#   df1 = pd.DataFrame(distance, columns = ['hospital_name','hosp_id','address', 'lat', 'lng', 'type_id','distance', 'is_ER'])
  
#   # sorting values based on distance 
#   df1 = df1.sort_values(by=['distance'])
 
#   # selecting only top 8
#   top8_hosp = df1.head(8)

#   # get wait time
#   curr_wt = []
#   for i in range(top8_hosp.shape[0]):
#     curr_wt.extend(get_wait_times(top8_hosp.iloc[i]['hosp_id'], top8_hosp.iloc[i]['is_ER']))
    
#   top8_hosp['wait_time'] = curr_wt[0]
#   top8_hosp['other_val'] = curr_wt[1]


#   # if is_ER and current_Time is after 6 then 0; since ERs are 24/7 open

#   # call KNN Imputer
#   check_nan = top8_hosp['wait_time'].isna().any()
#   check_all_nan = top8_hosp['wait_time'].isna().all()

#   if ~check_all_nan:
#     if check_nan:
#       return Knn_imputer(top8_hosp)
#       #return top8_hosp
#     else:
#       return top8_hosp
#   else:
#     # if all Nan values in wait time and irrespective of ER or not
#     top8_hosp['wait_time'] = 0
#     return top8_hosp

def cal_time_taken(usr_lat, usr_lng, df):

  time_taken = []
  for a in range(df.shape[0]):
    lat_1 = df.iloc[a]['lat']
    lon_1 = df.iloc[a]['lng']
    lat_2 = usr_lat
    lon_2 = usr_lng

    # request to OSRM API
    r = requests.get(f"http://router.project-osrm.org/route/v1/car/{lon_1},{lat_1};{lon_2},{lat_2}?overview=false""")

    # then you load the response using the json libray
    # by default you get only one alternative so you access 0-th element of the `routes`
    routes = json.loads(r.content)
    route_1 = routes.get("routes")[0]
    time_taken.append(route_1["duration"])
    #time_taken.append(str(timedelta(seconds = route_1["duration"])))

  df['time_taken'] = time_taken

  return df

def get_wait_times_df(hosp_id):
  from datetime import datetime
  
  raw_history ={}
  other_val = False

  root_url= "https://ertrack.net/"
  url = "/api/hospital/"+str(hosp_id)+"/history/"
  url = urljoin(root_url, url)

  UTC = pytz.utc
  datetime_utc = datetime.now(UTC)

  try:
    r = requests.get(url)
    r.raise_for_status()

  except HTTPError as exc:
    code = exc.response.status_code
    if code in [200, 429, 500, 502, 503, 504]:
      wait_time = -2
      obs_time = datetime_utc.strftime('%Y-%m-%d %H:%M:%S%z')
      return -2

  else:
    for k, v in r.json().items():
        raw_history[k] = [parse(i) for i in v]
    #convert dict to dataframe 
    df_rh = pd.DataFrame.from_dict(raw_history, orient='index').transpose()

  return df_rh

def get_next_wait_time(df):

  next_wait_time = []
  
  for i in range(df.shape[0]):

    wait_time = df.iloc[i]['wait_time']
    # only for wait times other than -1 or -2 or -5
    pred = 0
    if wait_time not in [-1, -2, -5]:

      #get the wait time for hospital id
      df_wt = get_wait_times_df(df.iloc[i]['hosp_id'])

      if isinstance(df_wt, pd.DataFrame):
        # if error occured while retrieveing the wait time, then no dataframe returned
        df_wt_cv = df_wt
        alphas = list(range(1, 31))
        list_rmse = []
        for a in alphas:
            
            df_wt_cv['Rolling'] = df_wt_cv['wait_time_mins'].rolling(a).mean() 
            df_wt_cv['Rolling'] = df_wt_cv['Rolling'].fillna(0)
            rmse = sqrt(mean_squared_error(df_wt_cv['wait_time_mins'], df_wt_cv['Rolling'])) 
            list_rmse.append(rmse)

        best_alpha = list_rmse.index(min(list_rmse))+1
        pred = df_wt['wait_time_mins'].rolling(best_alpha).mean().iloc[-1]
        
        if pred == -1:
          all_val = df_wt['wait_time_mins'].unique()
          if len(all_val) > 1:
            pred = -5 # indicating closing
          else:
            pred = wait_time # since already KNN imputed

    next_wait_time.append(pred)

  df['next_wait_time'] = next_wait_time

  return df

def rank_according_to(data, candidates):
    ranks = rankdata(data).astype(int)
    ranks -= 1
    return candidates[ranks][::-1]

def get_topsis_algo(df):

  #weights
  weights = np.array([0.3, 0.5, 0.2])
  
  #candidates be the index number of the df
  candidates = np.array(df.index.values)


  # Normalized data
  m = len(df)
  n = len(df.columns)
  divisors = np.empty(n)
  for j in range(n):
      column = df.iloc[:,j]
      divisors[j] = np.sqrt(column @ column)

  df /= divisors


  # Weighted normalized data
  df *= weights


  # Identify best and worst example
  benefit_attributes = set([0, 1, 2])
  a_pos = np.zeros(n)
  a_neg = np.zeros(n)
  for j in range(n):
      column = df.iloc[:,j]
      max_val = np.max(column)
      min_val = np.min(column)
      
      # See if we want to maximize benefit or minimize cost (for PIS)
      if j in benefit_attributes:
          a_neg[j] = max_val
          a_pos[j] = min_val
      else:
          a_pos[j] = max_val
          a_neg[j] = min_val


  # Calculating Separation Measures and Similarities to PIS
  sp = np.zeros(m)
  sn = np.zeros(m)
  cs = np.zeros(m)

  for i in range(m):
      diff_pos = df.iloc[i] - a_pos
      diff_neg = df.iloc[i] - a_neg
      sp[i] = np.sqrt(diff_pos @ diff_pos)
      sn[i] = np.sqrt(diff_neg @ diff_neg)
      cs[i] = sn[i] / (sp[i] + sn[i])

  # Ranking the candidates/alternatives
  cs_order = rank_according_to(cs, candidates)
  sp_order = rank_according_to(sp, candidates)
  sn_order = rank_according_to(sn, candidates)
  
  return pd.DataFrame(data=cs_order, columns = ['indices']).head(3)

def seconder(x):
    mins= x
    td = timedelta(minutes=mins)
    return td.total_seconds()

def get_wt(user_lat, user_lng, df):
  
  # Fetch state from lat and long
  # geolocator = Nominatim(user_agent="Geolocation")
  # location = geolocator.reverse(str(user_lat)+","+str(user_lng))
  # address = location.raw['address']
  # state = address.get('state', '')

  # # get the state code fromt he state name
  # state_code = us_state_to_abbrev.get(state)

  url = f'https://nominatim.openstreetmap.org/reverse?lat={user_lat}&lon={user_lng}&format=json&namedetails=1&accept-language=en&zoom=5'
  result = requests.get(url=url)
  result_json = result.json()
  state_code= result_json['namedetails']['ref'].upper()

  # get the list of neighbouring states
  state_list = neigh_state.get(state_code)
  state_list.append(state_code)

  # filtering data only for that states
  df_req = df[df.state.isin(state_list)]

  distance = []

  for i in range(df_req.shape[0]):
    # lat and lng of hospitals from state
    lat_lng_hosp = df_req.iloc[i]['lat'], df_req.iloc[i]['lng']

    # lat and lng of user
    lat_lng_user = user_lat, user_lng

    # distance calculated in miles
    cal_dist = geodesic(lat_lng_user, lat_lng_hosp).miles


    hosp = df_req.iloc[i]['hospital_name'] 
    hosp_id = df_req.iloc[i]['hospital_id']
    hosp_add = df_req.iloc[i]['address']
    lat = df_req.iloc[i]['lat']
    lng = df_req.iloc[i]['lng']
    hosp_type = df_req.iloc[i]['type_id']
    is_ER = df_req.iloc[i]['Is_ER']
    
    # appending all values to the list
    distance.append([hosp, hosp_id, hosp_add,lat, lng, hosp_type, cal_dist, is_ER])

  # converting the list to dataframe
  df_an = pd.DataFrame(distance, columns = ['hospital_name','hosp_id','address', 'lat', 'lng', 'type_id','distance', 'is_ER'])
  # sorting values based on distance 
  df_an = df_an.sort_values(by=['distance']) 

  # selecting only top 8
  top8_hosp = df_an.head(8) 

  # get wait time
  curr_wt = []
  for i in range(top8_hosp.shape[0]):
    curr_wt.append(list(get_wait_times(top8_hosp.iloc[i]['hosp_id'], top8_hosp.iloc[i]['is_ER'])))

  wait_times = [item[0] for item in curr_wt]
  other_val = [item[1] for item in curr_wt]  

  top8_hosp['wait_time'] = wait_times
  top8_hosp['other_val'] = other_val

  # call KNN Imputer
  check_nan = top8_hosp['wait_time'].isna().any()
  check_all_nan = top8_hosp['wait_time'].isna().all()

  if ~check_all_nan:
    if check_nan:
      top8_hosp =  Knn_imputer(top8_hosp)
  else:
    # if all Nan values in wait time and irrespective of ER or not
    top8_hosp['wait_time'] = 0

  return top8_hosp

def final_call(user_lat, user_lng):

  # Fetching data for all hospitals
  urllib.request.urlretrieve('https://ertrack.net/api/hospitals/', 'hospital_array.json')
  hospital_array = open('hospital_array.json')
  df_all_hospitals = pd.read_json('hospital_array.json')

  # removing hospitals where the longitude and latitude are None
  df_all_hospitals = df_all_hospitals[df_all_hospitals['lat'] != 'None']

  # remove # from address column
  df_all_hospitals['address'] = df_all_hospitals['address'].apply(remove_unwanted_chars)

  # Adding a new column to check whether the hospitals are ER or not
  #df_all_hospitals['Is_ER'] = df_all_hospitals['hospital_name'].str.contains('ER').map({True: 'yes', False: 'no'})
  df_all_hospitals['Is_ER'] = df_all_hospitals['hospital_name'].str.contains('ER')


  #
  top8_hosp = get_wt(user_lat, user_lng, df_all_hospitals)


  #cal_time_taken()
  df_tt = cal_time_taken(user_lat, user_lng, top8_hosp)


  #get_next_wait_time()
  df_with_pred = get_next_wait_time(df_tt)


  # if zeros then replace by 1
  df_with_pred['next_wait_time'] = df_with_pred['next_wait_time'].replace(0,1)

  #get_topsis_algo()
  df_topsis = df_with_pred[['next_wait_time', 'distance', 'time_taken']]
  df_top3_idx = get_topsis_algo(df_topsis)



  df_top3_list = df_top3_idx['indices'].values.tolist()
  final_list =[]
  for i in range(0,3):
    idx = df_top3_list[i]
    final_list.append(df_with_pred.loc[idx])


  final_df = pd.DataFrame(final_list)

  # next_wait_time into seconds
  final_df['next_wait_time_sec'] = final_df['next_wait_time'].apply(seconder)

  # total_wait_time = time_taken + next_wait_time_sec
  final_df['total_wait_time'] = final_df['time_taken'] + final_df['next_wait_time_sec']
  final_df['hospital'] = final_df['hospital_name'] + "  " + final_df['address']
  
  # convert into hour:minutes:secs format
  final_df['total_mins'] = final_df['total_wait_time'].astype('datetime64[s]').dt.strftime("%H:%M:%S")

  return final_df[['hospital', 'total_mins']].values.tolist()


